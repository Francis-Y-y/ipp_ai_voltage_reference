{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fddd76f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model as lm\n",
    "import torch\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import torch.nn as nn\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.client import device_lib \n",
    "\n",
    "from sklearn.svm import LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4237327a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predicted, actual):\n",
    "    return np.sqrt(np.mean((actual - predicted)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5e4d9480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 41638182912.0000 - val_loss: 663056.9375\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 375537.9062 - val_loss: 418324.5312\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 394452.8750 - val_loss: 434307.1875\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 400298.3125 - val_loss: 432975.4688\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 427341.3438 - val_loss: 480344.3125\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 437723.1250 - val_loss: 497633.2188\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 409787.2812 - val_loss: 453432.1562\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 422420.3750 - val_loss: 467233.0625\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 477663.1250 - val_loss: 403317.0312\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 506774.4375 - val_loss: 3170328.5000\n",
      "46/46 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 300280971264.0000 - val_loss: 1535862.3750\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 1172913.0000 - val_loss: 1128798.6250\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 1114029.5000 - val_loss: 1138548.6250\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 1145742.2500 - val_loss: 1199389.6250\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 1313940.0000 - val_loss: 1465513.7500\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 1234807.8750 - val_loss: 1038507.3125\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 1220437.7500 - val_loss: 1578542.3750\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 1393752.1250 - val_loss: 1034638.0000\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 1492136.3750 - val_loss: 2272040.5000\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 1396463.6250 - val_loss: 2526620.5000\n",
      "46/46 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 978345394176.0000 - val_loss: 1530261.2500\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 646196.3125 - val_loss: 640769.6875\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 634054.9375 - val_loss: 824697.0625\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 636194.2500 - val_loss: 703254.0625\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 634329.8750 - val_loss: 640864.1250\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 662960.0625 - val_loss: 965872.2500\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 642187.3750 - val_loss: 584422.9375\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 630420.3750 - val_loss: 570982.6250\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 642440.5000 - val_loss: 682103.5625\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 647655.6875 - val_loss: 694031.3125\n",
      "46/46 [==============================] - 0s 1ms/step\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 18229950464.0000 - val_loss: 5922375.5000\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 7494866.0000 - val_loss: 17323212.0000\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 10087776.0000 - val_loss: 7041166.5000\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 7766242.5000 - val_loss: 61935464.0000\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 13311882.0000 - val_loss: 44200104.0000\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 22192450.0000 - val_loss: 7269019.0000\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 11335360.0000 - val_loss: 130541136.0000\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 33240758.0000 - val_loss: 75276704.0000\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 60177240.0000 - val_loss: 5309963.0000\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 181513952.0000 - val_loss: 4395716.0000\n",
      "46/46 [==============================] - 0s 998us/step\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 3520249462784.0000 - val_loss: 5962647.0000\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 4711641.5000 - val_loss: 3850204.2500\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 4761866.0000 - val_loss: 4695853.0000\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 4843829.5000 - val_loss: 3776742.5000\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 4703074.0000 - val_loss: 3739096.7500\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 4768475.5000 - val_loss: 4662718.0000\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 4887629.5000 - val_loss: 4572569.0000\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 4823358.0000 - val_loss: 5095971.5000\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 5151127.0000 - val_loss: 3986730.0000\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 4893975.0000 - val_loss: 3894831.0000\n",
      "46/46 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8431.216681164116"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "shuffled_data = shuffle(data).reset_index(drop=True)\n",
    "#shuffled_data.head()\n",
    "#shuffled_data.loc[0]\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "total_error = 0\n",
    "\n",
    "for train, test in kf.split(shuffled_data):\n",
    "    \n",
    "    train_data = shuffled_data.loc[train]\n",
    "    validate_data = shuffled_data.loc[test]\n",
    "    \n",
    "    y_train = train_data['polarity']\n",
    "    x_train = train_data.iloc[:, 1:12]\n",
    "    \n",
    "    y_v = validate_data['polarity']\n",
    "    x_v = validate_data.iloc[:, 1:12]\n",
    "    \n",
    "    y_v_numpy = y_v.to_numpy()\n",
    "\n",
    "    # SVR model\n",
    "    #svr_predicted = svr(x_train, y_train, x_v, 10, 0.1)\n",
    "    \n",
    "    # MLP model\n",
    "    mlp_predicted = MLP(x_train, y_train, x_v)\n",
    "\n",
    "    \n",
    "    total_error = total_error + rmse(mlp_predicted, y_v_numpy)\n",
    "    \n",
    "total_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2532b1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model_name)\n",
    "    for train, test in kf.split(shuffled_data):\n",
    "        train_data = shuffled_data.loc[train]\n",
    "        validate_data = shuffled_data.loc[test]\n",
    "        y_train = train_data['polarity']\n",
    "        x_train = train_data.iloc[:, 1:12]\n",
    "        y_v = validate_data['polarity']\n",
    "        x_v = validate_data.iloc[:, 1:12]\n",
    "        y_v_numpy = y_v.to_numpy()\n",
    "\n",
    "        if model_name == 'SVR':\n",
    "            # SVR model\n",
    "            svr_predicted = svr(x_train, y_train, x_v, 10, 0.1)\n",
    "\n",
    "        elif model_name == 'MLP':\n",
    "            # MLP model\n",
    "            mlp_predicted = MLP(x_train, y_train, x_v)\n",
    "\n",
    "\n",
    "        total_error = total_error + rmse(mlp_predicted, y_v_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e44064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svr(x_train, y_train, x_v, eps, c):\n",
    "    svr = LinearSVR(epsilon=eps, C=c, fit_intercept=True)\n",
    "    svr.fit(x_train, y_train)\n",
    "    svr_predicted = svr.predict(x_v)\n",
    "\n",
    "    return svr_predicted\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65ca1d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no.</th>\n",
       "      <th>v+</th>\n",
       "      <th>v-</th>\n",
       "      <th>vv</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>R3</th>\n",
       "      <th>I3(nA)</th>\n",
       "      <th>R2/R1</th>\n",
       "      <th>R3/R1</th>\n",
       "      <th>R3/R2</th>\n",
       "      <th>vv/[(v+)-(v-)]</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.395032</td>\n",
       "      <td>0.393743</td>\n",
       "      <td>0.378640</td>\n",
       "      <td>21572414.74</td>\n",
       "      <td>21572414.74</td>\n",
       "      <td>1920840.568</td>\n",
       "      <td>63.867004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.089042</td>\n",
       "      <td>0.089042</td>\n",
       "      <td>293.616407</td>\n",
       "      <td>0.077872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.382076</td>\n",
       "      <td>0.378545</td>\n",
       "      <td>0.393967</td>\n",
       "      <td>29037202.25</td>\n",
       "      <td>29037202.25</td>\n",
       "      <td>2553017.942</td>\n",
       "      <td>46.184081</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.087922</td>\n",
       "      <td>0.087922</td>\n",
       "      <td>111.562104</td>\n",
       "      <td>0.099350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.361179</td>\n",
       "      <td>0.357530</td>\n",
       "      <td>0.417032</td>\n",
       "      <td>24870699.23</td>\n",
       "      <td>24870699.23</td>\n",
       "      <td>2187843.247</td>\n",
       "      <td>49.910705</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.087969</td>\n",
       "      <td>0.087969</td>\n",
       "      <td>114.276679</td>\n",
       "      <td>0.108427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.377965</td>\n",
       "      <td>0.374717</td>\n",
       "      <td>0.400799</td>\n",
       "      <td>27812575.93</td>\n",
       "      <td>27812575.93</td>\n",
       "      <td>2485072.157</td>\n",
       "      <td>45.546246</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.089351</td>\n",
       "      <td>0.089351</td>\n",
       "      <td>123.402273</td>\n",
       "      <td>0.153662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.386587</td>\n",
       "      <td>0.384328</td>\n",
       "      <td>0.387534</td>\n",
       "      <td>23690912.29</td>\n",
       "      <td>23690912.29</td>\n",
       "      <td>2093395.335</td>\n",
       "      <td>56.853948</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.088363</td>\n",
       "      <td>0.088363</td>\n",
       "      <td>171.560867</td>\n",
       "      <td>0.117408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no.       v+        v-        vv           R1           R2           R3   \\\n",
       "0    1  0.395032  0.393743  0.378640  21572414.74  21572414.74  1920840.568   \n",
       "1    2  0.382076  0.378545  0.393967  29037202.25  29037202.25  2553017.942   \n",
       "2    3  0.361179  0.357530  0.417032  24870699.23  24870699.23  2187843.247   \n",
       "3    4  0.377965  0.374717  0.400799  27812575.93  27812575.93  2485072.157   \n",
       "4    5  0.386587  0.384328  0.387534  23690912.29  23690912.29  2093395.335   \n",
       "\n",
       "      I3(nA)  R2/R1     R3/R1     R3/R2  vv/[(v+)-(v-)]  polarity  \n",
       "0  63.867004    1.0  0.089042  0.089042      293.616407  0.077872  \n",
       "1  46.184081    1.0  0.087922  0.087922      111.562104  0.099350  \n",
       "2  49.910705    1.0  0.087969  0.087969      114.276679  0.108427  \n",
       "3  45.546246    1.0  0.089351  0.089351      123.402273  0.153662  \n",
       "4  56.853948    1.0  0.088363  0.088363      171.560867  0.117408  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_forest(x_train, y_train, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a344fa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(x_train, y_train, x_v):\n",
    "    size, features = x_train.shape\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(features, ))\n",
    "    hidden = tf.keras.layers.Dense(64, activation='relu')(inputs)\n",
    "    hidden = tf.keras.layers.Dense(64, activation='relu')(hidden)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='linear')(hidden)\n",
    "\n",
    "    tf_model = tf.keras.Model(inputs, outputs)\n",
    "    tf_model.compile(\n",
    "        optimizer = 'adam',\n",
    "        loss = 'mse'\n",
    "    )\n",
    "\n",
    "    history = tf_model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        validation_split=0.12,\n",
    "        batch_size=32,\n",
    "        epochs=10\n",
    "    )\n",
    "    result = tf_model.predict(x_v)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002a2b48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
